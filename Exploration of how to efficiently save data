There are 3 alternatives methods to save the data. 1. pandas .csv file   2. numpy .npy file   3. image

After doing the experiment of saving the same file in all three ways and comparing the results, I draw the conclusion that .npy file is
the best.

We can get rid of image first. Even though we can consider image as a 2D array, the dtype of numbers is uint, which are integers.
Forcely turning float numbers to integers wastes a lot of information, so we have to give up this way.

Here's a code I found in kaggle competition.
def reduce_mem_usage(df):
    """ iterate through all the columns of a dataframe and modify the data type
        to reduce memory usage.        
    """
    start_mem = df.memory_usage().sum() / 1024**2
    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem)
    for col in df.columns:
        col_type = df[col].dtypes
        if col_type != object:
            c_min = df[col].min()
            c_max = df[col].max()
            if str(col_type)[:3] == 'int':
                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:
                    df[col] = df[col].astype(np.int8)
                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:
                    df[col] = df[col].astype(np.int16)
                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:
                    df[col] = df[col].astype(np.int32)
                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:
                    df[col] = df[col].astype(np.int64)  
            else:
                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:
                    df[col] = df[col].astype(np.float16)
                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:
                    df[col] = df[col].astype(np.float32)
                else:
                    df[col] = df[col].astype(np.float64)
        #else: df[col] = df[col].astype('category')
    end_mem = df.memory_usage().sum() / 1024**2
    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))
    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))
    return df
https://www.kaggle.com/nicapotato/catboost-aggregate-features/code

The number in .csv files are defaultly saved in float64 form. However, the form of float64 wastes space since most numbers don't need so
much. By applying the code above, we can save numbers in the way costing least space.

As I mentioned before, .csv files defaultly save numbers in float64 form(don't know if there is another way of saving numbers), which
uses more storage, but .npy allows users to save numbers in any forms (eg. float16, int16). In this experiment, the size of the .file
is 15mb while after applying the code above (which changes the dtype of the array to float16), the .npy file only costs 3.82mb. 
Therefore, I'd like to use .npy.

This is just one experiment and I'm not sure if there're exceptions. If you have any assumptions, feel free to test by yourself and
please share your results.

Enjoy learning technology and design.
